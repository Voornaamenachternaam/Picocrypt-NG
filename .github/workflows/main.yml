name: "AI inference (MCP enabled)"
on:
  pull_request:
    types: [opened, reopened, synchronize]

permissions:
  # minimal workflow permissions for calling Models + letting the action use repo read data
  contents: read
  pull-requests: read
  models: read

jobs:
  inference:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: AI Inference with GitHub Tools (MCP)
        id: inference
        uses: actions/ai-inference@v2.0.1
        with:
          prompt: "List my open pull requests and create a summary"
          # IMPORTANT: token is used for model inference calls (use the built-in token)
          token: ${{ github.token }}
          # github-mcp-token must be a PAT (fine-grained recommended), stored as a repo secret
          github-mcp-token: ${{ secrets.GH2_TOKEN }}
          enable-github-mcp: true
          model: openai/gpt-4o
          max-tokens: 400

      - name: Show model response
        run: |
          echo "=== AI response ==="
          echo "${{ steps.inference.outputs.response }}"
